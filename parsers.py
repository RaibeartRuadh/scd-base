# parsers.py
from bs4 import BeautifulSoup
import re
import requests
from models import db, Dance, DanceType, DanceFormat, SetType

class DancePageParser:
    def __init__(self, html_content):
        self.soup = BeautifulSoup(html_content, 'html.parser')
    
    def parse_dance_data(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö –æ —Ç–∞–Ω—Ü–µ"""
        data = {
            'name': self._parse_name(),
            'dance_type': self._parse_dance_type(),
            'meter': self._parse_meter(),
            'bars': self._parse_bars(),  # –∫–æ–¥ —Ç–∞–∫—Ç–æ–≤ (J48, R32)
            'bars_count': self._parse_bars_count(),  # —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–∞–∫—Ç–æ–≤ –¥–ª—è size_id
            'formation': self._parse_formation(),
            'couples_count': self._parse_couples_count(),
            'progression': self._parse_progression(),
            'repetitions': self._parse_repetitions(),  # —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –¥–ª—è count_id
            'author': self._parse_author(),
            'year': self._parse_year(),
            'description': self._parse_description(),
            'steps': self._parse_steps(),
            'published_in': self._parse_publications(),
            'recommended_music': self._parse_music(),
            'figures': self._parse_figures(),
            'extra_info': self._parse_extra_info(),
            'intensity': self._parse_intensity(),
            'formations_list': self._parse_formations_list(),
            'images': self._parse_images(),  # –í–ö–õ–Æ–ß–ê–ï–ú –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!
            'source_url': self._parse_source_url()  # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π URL
        }
        return data
    
    def _parse_name(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–∞–Ω—Ü–∞"""
        title_element = self.soup.find('span', {'id': 'title'})
        return title_element.get_text().strip() if title_element else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∞–Ω–µ—Ü'
    
    def _parse_dance_type(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–∏–ø–∞ —Ç–∞–Ω—Ü–∞ (Jig, Reel, etc)"""
        # –ò—â–µ–º –≤ –ø–µ—Ä–≤–æ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ –ø–æ—Å–ª–µ h1
        first_p = self.soup.find('h1')
        if first_p:
            first_p = first_p.find_next('p')
            if first_p:
                text = first_p.get_text()
                if 'Jig' in text:
                    return 'Jig'
                elif 'Reel' in text:
                    return 'Reel'
                elif 'Strathspey' in text:
                    return 'Strathspey'
                elif 'March' in text:
                    return 'March'
                elif 'Waltz' in text:
                    return 'Waltz'
                elif 'Polka' in text:
                    return 'Polka'
        return 'Unknown'
    
    def _parse_meter(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞–∑–º–µ—Ä–∞ (4/4L, 3/4, etc)"""
        first_p = self.soup.find('h1')
        if first_p:
            first_p = first_p.find_next('p')
            if first_p:
                text = first_p.get_text()
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "4/4L", "3/4"
                meter_match = re.search(r'(\d+/\d+[A-Z]*)', text)
                return meter_match.group(1) if meter_match else None
        return None
    
    def _parse_bars(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–¥–∞ —Ç–∞–∫—Ç–æ–≤ (J48, R32, etc) - –¥–ª—è –∑–∞–º–µ—Ç–∫–∏"""
        first_p = self.soup.find('h1')
        if first_p:
            first_p = first_p.find_next('p')
            if first_p:
                text = first_p.get_text()
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "J48", "R32"
                bars_match = re.search(r'([A-Z]\d+)', text)
                return bars_match.group(1) if bars_match else None
        return None
    
    def _parse_bars_count(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–∞–∫—Ç–æ–≤ (—á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è size_id)"""
        first_p = self.soup.find('h1')
        if first_p:
            first_p = first_p.find_next('p')
            if first_p:
                text = first_p.get_text()
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "32 bars", "48 bars" –∏ —Ç.–¥.
                bars_match = re.search(r'(\d+)\s*bars', text, re.IGNORECASE)
                if bars_match:
                    return int(bars_match.group(1))
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ "J48", "R32" –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ
        bars_code = self._parse_bars()
        if bars_code:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ –∫–æ–¥–∞ —Ç–∏–ø–∞ "J48", "R32"
            num_match = re.search(r'(\d+)', bars_code)
            if num_match:
                return int(num_match.group(1))
        
        return 32  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _parse_formation(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        first_p = self.soup.find('h1')
        if first_p:
            first_p = first_p.find_next('p')
            if first_p:
                text = first_p.get_text()
                if 'Longwise' in text:
                    return 'Longwise'
                elif 'Square' in text:
                    return 'Square'
                elif 'Triangular' in text:
                    return 'Triangular'
                elif 'Circular' in text:
                    return 'Circular'
        return 'Longwise'  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _parse_couples_count(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä"""
        first_p = self.soup.find('h1')
        if first_p:
            first_p = first_p.find_next('p')
            if first_p:
                text = first_p.get_text()
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "4 couples"
                couples_match = re.search(r'(\d+)\s+couples', text)
                if couples_match:
                    return int(couples_match.group(1))
                
                # –ò—â–µ–º –¥—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
                if '3 couples' in text.lower():
                    return 3
                elif '2 couples' in text.lower():
                    return 2
                elif '5 couples' in text.lower():
                    return 5
                elif '6 couples' in text.lower():
                    return 6
        return 4  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 4
    
    def _parse_progression(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–∏"""
        first_p = self.soup.find('h1')
        if first_p:
            first_p = first_p.find_next('p')
            if first_p:
                text = first_p.get_text()
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–∏ –≤ —Å–∫–æ–±–∫–∞—Ö
                prog_match = re.search(r'Progression:\s*(\d+)', text)
                return prog_match.group(1) if prog_match else None
        return None
    
    def _parse_repetitions(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π"""
        first_p = self.soup.find('h1')
        if first_p:
            first_p = first_p.find_next('p')
            if first_p:
                text = first_p.get_text()
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "Usual number of repetitions: 8"
                rep_match = re.search(r'repetitions:\s*(\d+)', text, re.IGNORECASE)
                if rep_match:
                    return int(rep_match.group(1))
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ–ø–∏—Å–∞–Ω–∏–∏, –∏—â–µ–º –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Å—Ç–∞—Ö
        dt_elements = self.soup.find_all('dt', class_='col-sm-2 text-sm-end')
        for dt in dt_elements:
            if 'repetitions' in dt.get_text().lower():
                dd = dt.find_next_sibling('dd')
                if dd:
                    text = dd.get_text()
                    rep_match = re.search(r'(\d+)', text)
                    if rep_match:
                        return int(rep_match.group(1))
        
        return 4  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _parse_author(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∞–≤—Ç–æ—Ä–∞"""
        dt_elements = self.soup.find_all('dt', class_='col-sm-2 text-sm-end')
        for dt in dt_elements:
            if 'Devised by' in dt.get_text():
                dd = dt.find_next_sibling('dd')
                if dd:
                    author_link = dd.find('a')
                    return author_link.get_text().strip() if author_link else 'Unknown'
        return 'Unknown'
    
    def _parse_year(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –≥–æ–¥–∞ —Å–æ–∑–¥–∞–Ω–∏—è"""
        dt_elements = self.soup.find_all('dt', class_='col-sm-2 text-sm-end')
        for dt in dt_elements:
            if 'Devised by' in dt.get_text():
                dd = dt.find_next_sibling('dd')
                if dd:
                    text = dd.get_text()
                    year_match = re.search(r'\((\d{4})\)', text)
                    return int(year_match.group(1)) if year_match else None
        return None
    
    def _parse_description(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–ø–∏—Å–∞–Ω–∏—è"""
        # –ò—â–µ–º –±–ª–æ–∫ —Å crib (–æ–ø–∏—Å–∞–Ω–∏–µ–º —Ñ–∏–≥—É—Ä)
        crib_div = self.soup.find('div', class_='cribtext')
        if crib_div:
            return crib_div.get_text().strip()
        return None
    
    def _parse_steps(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —à–∞–≥–æ–≤"""
        dt_elements = self.soup.find_all('dt', class_='col-sm-2 text-sm-end')
        for dt in dt_elements:
            if 'Steps' in dt.get_text():
                dd = dt.find_next_sibling('dd')
                if dd:
                    steps_text = dd.get_text().strip()
                    return [step.strip() for step in steps_text.split(',')]
        return []
    
    def _parse_publications(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        publications = []
        dt_elements = self.soup.find_all('dt', class_='col-sm-2 text-sm-end')
        for dt in dt_elements:
            if 'Published in' in dt.get_text():
                dd = dt.find_next_sibling('dd')
                if dd:
                    pub_links = dd.find_all('a')
                    for link in pub_links:
                        publications.append(link.get_text().strip())
        return publications
    
    def _parse_music(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–π –º—É–∑—ã–∫–∏"""
        music = []
        dt_elements = self.soup.find_all('dt', class_='col-sm-2 text-sm-end')
        for dt in dt_elements:
            if 'Recommended Music' in dt.get_text():
                dd = dt.find_next_sibling('dd')
                if dd:
                    music_links = dd.find_all('a')
                    for link in music_links:
                        music.append(link.get_text().strip())
        return music
    
    def _parse_figures(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∏–≥—É—Ä –ø–æ —Ç–∞–∫—Ç–∞–º"""
        figures = []
        crib_div = self.soup.find('div', class_='cribtext')
        if crib_div:
            # –ò—â–µ–º –≤—Å–µ dt/dd –ø–∞—Ä—ã –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
            dance_dl = crib_div.find('dl', class_='dance')
            if dance_dl:
                current_bars = None
                for element in dance_dl.children:
                    if element.name == 'dt':
                        current_bars = element.get_text().strip()
                    elif element.name == 'dd' and current_bars:
                        description = element.get_text().strip()
                        figures.append({
                            'bars': current_bars,
                            'description': description
                        })
                        current_bars = None
        return figures
    
    def _parse_extra_info(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –≤–∫–ª–∞–¥–∫–∏ Extra Info"""
        extra_info = ""
        
        # –ò—â–µ–º –≤–∫–ª–∞–¥–∫—É Extra Info –ø–æ ID
        extra_tab = self.soup.find('div', {'id': 'extrainfo'})
        if extra_tab:
            # –ò—â–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —ç—Ç–æ–π –≤–∫–ª–∞–¥–∫–µ
            elements = extra_tab.find_all(['p', 'div', 'span'])
            for element in elements:
                text = element.get_text().strip()
                if text and len(text) > 5:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã
                    if text not in extra_info:  # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                        extra_info += text + "\n\n"
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –±–µ—Ä–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
            if not extra_info.strip():
                text_content = extra_tab.get_text().strip()
                if text_content and len(text_content) > 10:
                    extra_info = text_content
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ —è–≤–Ω–æ–π –≤–∫–ª–∞–¥–∫–µ, –∏—â–µ–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ–ø–∏—Å–∞–Ω–∏–∏
        if not extra_info.strip():
            extra_dl = self.soup.find('dl', class_='row')
            if extra_dl:
                dt_elements = extra_dl.find_all('dt', class_='col-sm-2 text-sm-end')
                for dt in dt_elements:
                    if 'Extra Info' in dt.get_text():
                        dd = dt.find_next_sibling('dd')
                        if dd:
                            extra_info = dd.get_text().strip()
                            break
        
        return extra_info.strip()
    
    def _parse_intensity(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ —Ç–∞–Ω—Ü–∞"""
        dt_elements = self.soup.find_all('dt', class_='col-sm-2 text-sm-end')
        for dt in dt_elements:
            if 'Intensity' in dt.get_text():
                dd = dt.find_next_sibling('dd')
                if dd:
                    intensity_text = dd.get_text().strip()
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏
                    intensity_match = re.search(r'(\d+%)', intensity_text)
                    if intensity_match:
                        return intensity_match.group(1)
                    return intensity_text
        return None
    
    def _parse_formations_list(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ —Ñ–æ—Ä–º–∞—Ü–∏–π"""
        formations = []
        dt_elements = self.soup.find_all('dt', class_='col-sm-2 text-sm-end')
        for dt in dt_elements:
            if 'Formations' in dt.get_text():
                dd = dt.find_next_sibling('dd')
                if dd:
                    formation_links = dd.find_all('a')
                    for link in formation_links:
                        formation_name = link.get_text().strip()
                        if formation_name and formation_name not in formations:
                            formations.append(formation_name)
        return formations
    
    def _parse_source_url(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ URL (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)"""
        canonical_link = self.soup.find('link', {'rel': 'canonical'})
        if canonical_link and canonical_link.get('href'):
            return canonical_link.get('href')
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–∏—Å–∫–∞ URL
        og_url = self.soup.find('meta', {'property': 'og:url'})
        if og_url and og_url.get('content'):
            return og_url.get('content')
        
        return None

    def _parse_images(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –≤–∫–ª–∞–¥–∫–∏ Cribs"""
        images = []
        
        # –ò—â–µ–º –≤–∫–ª–∞–¥–∫—É Cribs –ø–æ ID
        cribs_tab = self.soup.find('div', {'id': 'cribs'})
        if not cribs_tab:
            print("‚ùå –í–∫–ª–∞–¥–∫–∞ Cribs –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return images
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –≤–∫–ª–∞–¥–∫–∞ Cribs")
        
        # –ò—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —ç—Ç–æ–π –≤–∫–ª–∞–¥–∫–µ
        img_elements = cribs_tab.find_all('img')
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Ç–µ–≥–æ–≤ img: {len(img_elements)}")
        
        for img in img_elements:
            src = img.get('src')
            if src:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ URL –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ
                full_url = self._make_absolute_url(src)
                alt = img.get('alt', 'Diagram')
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
                image_type = self._determine_image_type(full_url, alt)
                
                images.append({
                    'url': full_url,
                    'alt': alt,
                    'filename': self._extract_filename(src),
                    'type': image_type
                })
                print(f"üñºÔ∏è  –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({image_type}): {full_url}")
        
        # –¢–∞–∫–∂–µ –∏—â–µ–º SVG –æ–±—ä–µ–∫—Ç—ã
        svg_objects = cribs_tab.find_all('object', {'type': 'image/svg+xml'})
        for svg_obj in svg_objects:
            data = svg_obj.get('data')
            if data:
                full_url = self._make_absolute_url(data)
                images.append({
                    'url': full_url,
                    'alt': 'SVG Diagram',
                    'filename': self._extract_filename(data),
                    'type': 'diagram'
                })
                print(f"üñºÔ∏è  –ù–∞–π–¥–µ–Ω SVG: {full_url}")
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_links = cribs_tab.find_all('a', href=re.compile(r'\.(png|jpg|jpeg|gif|svg|webp)', re.I))
        for link in image_links:
            href = link.get('href')
            if href and href not in [img['url'] for img in images]:
                full_url = self._make_absolute_url(href)
                alt = link.get_text().strip() or 'Linked Diagram'
                image_type = self._determine_image_type(full_url, alt)
                
                images.append({
                    'url': full_url,
                    'alt': alt,
                    'filename': self._extract_filename(href),
                    'type': image_type
                })
                print(f"üñºÔ∏è  –ù–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({image_type}): {full_url}")
        
        print(f"üìä –ò—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}")
        return images

    def _determine_image_type(self, url, alt_text):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ URL –∏ alt —Ç–µ–∫—Å—Ç–∞"""
        alt_lower = alt_text.lower()
        url_lower = url.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ alt —Ç–µ–∫—Å—Ç—É
        if any(word in alt_lower for word in ['diagram', 'diag', '—Å—Ö–µ–º–∞', '–¥–∏–∞–≥—Ä–∞–º–º–∞']):
            return 'diagram'
        elif any(word in alt_lower for word in ['music', 'sheet', '–Ω–æ—Ç—ã', '–ø–∞—Ä—Ç–∏—Ç—É—Ä–∞']):
            return 'music'
        elif any(word in alt_lower for word in ['author', 'composer', '–∞–≤—Ç–æ—Ä', '–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä']):
            return 'author'
        elif any(word in alt_lower for word in ['formation', '—Ñ–æ—Ä–º–∞—Ü–∏—è', '–ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ']):
            return 'formation'
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ URL
        if any(word in url_lower for word in ['diagram', 'diag']):
            return 'diagram'
        elif any(word in url_lower for word in ['music', 'sheet']):
            return 'music'
        
        return 'diagram'  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º–æ–π

    def _make_absolute_url(self, relative_url):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–≥–æ URL –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π"""
        if relative_url.startswith('http'):
            return relative_url
        elif relative_url.startswith('//'):
            return 'https:' + relative_url
        elif relative_url.startswith('/'):
            return 'https://my.strathspey.org' + relative_url
        else:
            return 'https://my.strathspey.org/' + relative_url

    def _extract_filename(self, url):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–∑ URL"""
        if not url:
            return 'diagram.svg'
        
        # –£–¥–∞–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
        url = url.split('?')[0]
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        filename = url.split('/')[-1]
        
        # –ï—Å–ª–∏ –∏–º—è —Ñ–∞–π–ª–∞ –ø—É—Å—Ç–æ–µ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if not filename or '.' not in filename:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø–æ —Ç–∏–ø—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º svg –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if 'svg' in url.lower():
                return 'diagram.svg'
            else:
                return 'diagram.png'
        
        return filename


class BatchDanceParser:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–Ω—Ü–µ–≤"""
    
    def __init__(self):
        self.parsed_dances = []
        self.errors = []
    
    def parse_multiple_dances(self, html_contents):
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö HTML —Å—Ç—Ä–∞–Ω–∏—Ü"""
        for i, html_content in enumerate(html_contents):
            try:
                parser = DancePageParser(html_content)
                dance_data = parser.parse_dance_data()
                self.parsed_dances.append(dance_data)
            except Exception as e:
                self.errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–∞–Ω—Ü–∞ {i+1}: {str(e)}")
        
        return {
            'successful': self.parsed_dances,
            'errors': self.errors,
            'total_parsed': len(self.parsed_dances),
            'total_errors': len(self.errors)
        }


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def extract_dance_id_from_url(url):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID —Ç–∞–Ω—Ü–∞ –∏–∑ URL"""
    if not url:
        return None
    match = re.search(r'/dance/(\d+)/', url)
    return match.group(1) if match else None


def validate_dance_data(dance_data):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Ç–∞–Ω—Ü–∞"""
    errors = []
    
    if not dance_data.get('name') or dance_data['name'] == '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∞–Ω–µ—Ü':
        errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–Ω—Ü–∞")
    
    if not dance_data.get('author') or dance_data['author'] == 'Unknown':
        errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∞–≤—Ç–æ—Ä —Ç–∞–Ω—Ü–∞")
    
    if not dance_data.get('description'):
        errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–∞–Ω—Ü–∞")
    
    return errors


def format_dance_data_for_display(dance_data):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    formatted = {
        '–ù–∞–∑–≤–∞–Ω–∏–µ': dance_data.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–¢–∏–ø': dance_data.get('dance_type', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–†–∞–∑–º–µ—Ä': dance_data.get('meter', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–ö–æ–¥ —Ç–∞–∫—Ç–æ–≤': dance_data.get('bars', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–∫—Ç–æ–≤': dance_data.get('bars_count', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–ê–≤—Ç–æ—Ä': dance_data.get('author', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–ì–æ–¥': dance_data.get('year', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–ü–∞—Ä—ã': f"{dance_data.get('couples_count', 4)} –ø–∞—Ä—ã",
        '–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ': dance_data.get('formation', 'Longwise'),
        '–ü—Ä–æ–≥—Ä–µ—Å—Å–∏—è': dance_data.get('progression', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–ü–æ–≤—Ç–æ—Ä–µ–Ω–∏—è': dance_data.get('repetitions', 4),
        '–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å': dance_data.get('intensity', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
        '–®–∞–≥–∏': ', '.join(dance_data.get('steps', [])),
        '–ü—É–±–ª–∏–∫–∞—Ü–∏–∏': ', '.join(dance_data.get('published_in', [])),
        '–ú—É–∑—ã–∫–∞': ', '.join(dance_data.get('recommended_music', [])),
        '–§–æ—Ä–º–∞—Ü–∏–∏': ', '.join(dance_data.get('formations_list', [])),
        '–§–∏–≥—É—Ä': len(dance_data.get('figures', [])),
        '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π': len(dance_data.get('images', [])),
        '–î–æ–ø. –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è': dance_data.get('extra_info', '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')[:100] + '...' if dance_data.get('extra_info') else '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'
    }
    
    return formatted